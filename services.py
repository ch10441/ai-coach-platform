# íŒŒì¼ëª…: services.py (self ì˜¤ë¥˜ í•´ê²°ëœ ìµœì¢… ë²„ì „)

import os
import json
import pinecone
import google.generativeai as genai
from dotenv import load_dotenv
from pypdf import PdfReader
from docx import Document

# [ìˆ˜ì •ë¨] _chunk_text í•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ ë°”ê¹¥ì˜ ë…ë¦½ì ì¸ 'ë„ìš°ë¯¸ í•¨ìˆ˜'ë¡œ ë§Œë“­ë‹ˆë‹¤.
# ì´ì œ ì´ í•¨ìˆ˜ëŠ” 'self'ë¥¼ í•„ìš”ë¡œ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
def _chunk_text(text, chunk_size=2000, chunk_overlap=200):
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì •í•´ì§„ í¬ê¸°ë¡œ, ì•½ê°„ì”© ê²¹ì¹˜ê²Œ í•˜ì—¬ ìë¥´ëŠ” í•¨ìˆ˜"""
    if not isinstance(text, str):
        return []
    
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - chunk_overlap
    return chunks


class AICoachingService:
    def __init__(self):
        load_dotenv()
        self.pinecone_api_key = os.getenv("PINECONE_API_KEY")
        self.pinecone_env = os.getenv("PINECONE_ENVIRONMENT")
        self.google_api_key = os.getenv("GOOGLE_API_KEY")

        if not all([self.pinecone_api_key, self.pinecone_env, self.google_api_key]):
            raise ValueError("ì´ˆê¸°í™” ì‹¤íŒ¨: Pinecone ë˜ëŠ” Google API í‚¤/í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        genai.configure(api_key=self.google_api_key)
        
        self.pinecone = pinecone.Pinecone(api_key=self.pinecone_api_key)
        self.index_name = "insurance-coach"
        self.embedding_model = 'models/text-embedding-004'
        
        self._initialize_pinecone_index()

        self.model = genai.GenerativeModel('gemini-1.5-pro-latest', generation_config={"response_mime_type": "application/json"})
        print("âœ… AI ì½”ì¹­ ì„œë¹„ìŠ¤ê°€ (Pineconeê³¼ í•¨ê»˜) ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def _initialize_pinecone_index(self):
        """Pinecone ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•˜ê³ , ë¹„ì–´ìˆìœ¼ë©´ knowledge_files í´ë”ì˜ ë¬¸ì„œë“¤ë¡œ ì±„ì›ë‹ˆë‹¤."""
        if self.index_name not in self.pinecone.list_indexes().names():
             raise ValueError(f"Pineconeì— '{self.index_name}' ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. Pinecone ëŒ€ì‹œë³´ë“œì—ì„œ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        
        self.index = self.pinecone.Index(self.index_name)
        stats = self.index.describe_index_stats()
        
        if stats['total_vector_count'] == 0:
            print(f"Pinecone ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆì–´, ì§€ì‹ ë² ì´ìŠ¤ë¡œ ì±„ì›ë‹ˆë‹¤...")
            KNOWLEDGE_DIR = "knowledge_files"
            all_chunks_with_source = []
            if os.path.exists(KNOWLEDGE_DIR):
                print(f"'{KNOWLEDGE_DIR}' í´ë”ì—ì„œ ë¬¸ì„œë¥¼ ì½ìŠµë‹ˆë‹¤...")
                for filename in os.listdir(KNOWLEDGE_DIR):
                    filepath = os.path.join(KNOWLEDGE_DIR, filename)
                    full_text = ""
                    if filename.endswith(".pdf"):
                        try:
                            reader = PdfReader(filepath)
                            full_text = "".join(page.extract_text() for page in reader.pages if page.extract_text())
                        except Exception as e: print(f"ğŸ”¥ PDF íŒŒì¼ '{filename}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    elif filename.endswith(".docx"):
                        try:
                            doc = Document(filepath)
                            full_text = "\n".join([para.text for para in doc.paragraphs])
                        except Exception as e: print(f"ğŸ”¥ DOCX íŒŒì¼ '{filename}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                    if full_text.strip():
                        # [ìˆ˜ì •ë¨] ì´ì œ self ì—†ì´ ë…ë¦½ì ì¸ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                        chunks_from_file = _chunk_text(full_text)
                        for chunk in chunks_from_file:
                            all_chunks_with_source.append({"text": chunk, "source": filename})
                        print(f"  - '{filename}' íŒŒì¼ì—ì„œ {len(chunks_from_file)}ê°œì˜ ì •ë³´ ì¡°ê° ìƒì„± ì™„ë£Œ.")
            
            if all_chunks_with_source:
                print(f"ì´ {len(all_chunks_with_source)}ê°œì˜ ì •ë³´ ì¡°ê°ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤...")
                
                just_texts = [item['text'] for item in all_chunks_with_source]
                embeddings = genai.embed_content(model=self.embedding_model, content=just_texts)['embedding']
                
                vectors_to_upsert = []
                for i, (embedding, item) in enumerate(zip(embeddings, all_chunks_with_source)):
                    metadata = {"text": item['text'], "source_file": item['source']}
                    vectors_to_upsert.append(pinecone.Vector(id=f"doc_chunk_{i}", values=embedding, metadata=metadata))
                
                batch_size = 100
                for i in range(0, len(vectors_to_upsert), batch_size):
                    batch = vectors_to_upsert[i:i + batch_size]
                    self.index.upsert(vectors=batch)
                print(f"âœ… Pinecone ì¸ë±ìŠ¤ì— {len(vectors_to_upsert)}ê°œì˜ ì •ë³´ ì¡°ê° ì €ì¥ ì™„ë£Œ.")
            else:
                print("âš ï¸ ê²½ê³ : 'knowledge_files' í´ë”ì— ë¶„ì„í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"âœ… RAG DB '{self.index_name}'ì— ì´ë¯¸ {stats['total_vector_count']}ê°œì˜ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
    
    def retrieve_relevant_knowledge(self, query, top_k=3):
        if not query.strip(): return []
        query_embedding = genai.embed_content(model=self.embedding_model, content=[query])['embedding'][0]
        results = self.index.query(vector=query_embedding, top_k=top_k, include_metadata=True)
        return [match['metadata']['text'] for match in results['matches']]

    def _build_prompt(self, consultation_text, history, relevant_knowledge):
        # í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì€ ì´ì „ ìµœì¢…ë³¸ê³¼ ë™ì¼í•©ë‹ˆë‹¤.
        history_str = "\n".join(history) if history else "ì—†ìŒ"
        knowledge_str = "\n---\n".join(relevant_knowledge) if relevant_knowledge else "ì°¸ê³ í•  ë§Œí•œ ì „ë¬¸ê°€ ì§€ì‹ ì—†ìŒ"
        return f"""
        [ì—­í•  ë° í˜ë¥´ì†Œë‚˜]
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë³´í—˜ ì„¸ì¼ì¦ˆ ì „ë¬¸ê°€ì´ì, ì‹ ì… ì„¤ê³„ì‚¬ì˜ ì„±ì¥ì„ ë•ëŠ” 'AI ì½”ì¹­ í”„ë¡œ'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì½”ì¹­ ìŠ¤íƒ€ì¼ì€ ì‹¬ë¦¬í•™ì— ê¸°ë°˜í•˜ì—¬ ê³ ê°ì˜ ë§ˆìŒì„ ì–»ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ë©°, í•­ìƒ ê¸ì •ì ì´ê³  ì „ëµì ì¸ ê´€ì ì—ì„œ ì¡°ì–¸í•©ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì¡°ì–¸ì€ ì ˆëŒ€ ë”±ë”±í•˜ê±°ë‚˜ ì‚¬ë¬´ì ì´ì§€ ì•Šê³ , ì‹¤ì œ ëŒ€í™”ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•´ì•¼ í•©ë‹ˆë‹¤.

        [ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™]
        - ìƒë‹´ ë‚´ìš©ì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
        - [â— ì¤‘ìš”] `recommended_actions` ë°°ì—´ ì•ˆì˜ ê° í•­ëª©ì˜ `style` ê°’ì€ ë°˜ë“œì‹œ ì„œë¡œ ë‹¬ë¼ì•¼ í•˜ë©°, 'ê³µê°', 'ì •ë³´ì œê³µ', 'ì§ˆë¬¸'ì˜ ì„¸ ê°€ì§€ í•µì‹¬ ì¹´í…Œê³ ë¦¬ë¥¼ ê°ê° ëŒ€í‘œí•´ì•¼ í•©ë‹ˆë‹¤.
        - [â— ì¤‘ìš”] ëª¨ë“  ì¶”ì²œ ë©˜íŠ¸("script")ëŠ” ê³ ê°ì˜ ë§ˆìŒì„ ì›€ì§ì¼ ìˆ˜ ìˆë„ë¡, ìµœì†Œ 3ì¤„ì—ì„œ 5ì¤„ ì‚¬ì´ì˜ í’ë¶€í•˜ê³  ìƒì„¸í•˜ë©° ì§„ì‹¬ì´ ë‹´ê¸´ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        - ë²•ì  ë˜ëŠ” ê·œì œìƒ ë¯¼ê°í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì€ ë‹¨ì •ì ìœ¼ë¡œ í‘œí˜„í•˜ì§€ ë§ê³ , "ì¼ë°˜ì ìœ¼ë¡œ" ë˜ëŠ” "ì˜ˆë¥¼ ë“¤ì–´"ì™€ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
        - ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•  ê²½ìš°, ê° JSON ê°’ì— 'ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ëª…í™•íˆ ì‘ë‹µí•˜ì„¸ìš”.
        - ë©˜íŠ¸ ìŠ¤íƒ€ì¼ì„ ì¤‘ë³µí•´ì„œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.

        [ë¶„ì„ ì ˆì°¨ (ë§¤ìš° ì¤‘ìš”)]
        ë‹¹ì‹ ì€ ë‹¤ìŒì˜ 4ë‹¨ê³„ ì‚¬ê³  ê³¼ì •ì„ ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.

        **1ë‹¨ê³„: ê³ ê° ì‹¬ì¸µ ë¶„ì„ (Deeper Customer Analysis)**
        - ê³ ê°ì˜ í˜„ì¬ ë°œì–¸ì„ ì‚¬ì‹¤ ê·¸ëŒ€ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ì–´ë–¤ ë‹¨ì–´ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€? ë¬´ì—‡ì„ ì§ì ‘ì ìœ¼ë¡œ ì§ˆë¬¸í–ˆëŠ”ê°€?
        - ê·¸ ë°œì–¸ì— ë‹´ê¸´ ê³ ê°ì˜ ì§„ì§œ 'ê°ì •(Sentiment)'ê³¼ 'ìˆ¨ê²¨ì§„ ì˜ë„(Intent)'ëŠ” ë¬´ì—‡ì¸ê°€?
        - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í¬í•¨í•œ ì „ì²´ ë§¥ë½ì„ í†µí•´ ê³ ê°ì˜ 'ì„±í–¥(Profile)'ì„ ì¶”ë¡ í•©ë‹ˆë‹¤. (ì˜ˆ: ê¼¼ê¼¼í•˜ê²Œ ë”°ì§€ëŠ” ë¶„ì„í˜•, ê´€ê³„ë¥¼ ì¤‘ì‹œí•˜ëŠ” ìš°í˜¸í˜• ë“±)

        **2ë‹¨ê³„: ë§¥ë½ ë° ë°ì´í„° ì—°ê²° (Context & Data Connection)**
        - 1ë‹¨ê³„ ë¶„ì„ ê²°ê³¼ë¥¼, ì œê³µëœ '[ë¶„ì„ì— ì°¸ê³ í•  ì „ë¬¸ê°€ ì§€ì‹ (RAG ê²°ê³¼)]'ì™€ ì—°ê²°í•©ë‹ˆë‹¤.
        - "ì´ ê³ ê°ì˜ ìƒí™©ì´ ìš°ë¦¬ íšŒì‚¬ì˜ ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€ ì¤‘ ì–´ë–¤ ê²ƒê³¼ ìœ ì‚¬í•œê°€?"
        - "ì´ ê³ ê°ì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ 'ë¹„ë²• ë…¸íŠ¸'ì—ì„œ ì–´ë–¤ ë‚´ìš©ì„ ì°¸ê³ í•´ì•¼ í•˜ëŠ”ê°€?"

        **3ë‹¨ê³„: í•µì‹¬ ë¬¸ì œ(ë°˜ë¡ ) ì •ì˜ ë° ì „ëµ ìˆ˜ë¦½ (Problem Definition & Strategy Formulation)**
        - 1, 2ë‹¨ê³„ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬, í˜„ì¬ ìƒë‹´ì„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„ì „ì‹œí‚¤ê¸° ìœ„í•´ í•´ê²°í•´ì•¼ í•  'ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ë¬¸ì œ' ë˜ëŠ” 'ì˜ˆìƒë˜ëŠ” ê³ ê°ì˜ í•µì‹¬ ë°˜ë¡ 'ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
        - ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ 'ëŒ€ì‘ ì „ëµ'ì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤. (ì˜ˆ: 'ë¹„ìš© ì €í•­ì´ë¯€ë¡œ, ê°€ì¹˜ì— ì´ˆì ì„ ë§ì¶° ì„¤ëª…í•˜ëŠ” ì „ëµ', 'ê²°ì •ì¥ì• ë¥¼ ë³´ì´ë¯€ë¡œ, ì„ íƒì§€ë¥¼ 2ê°œë¡œ ì¢í˜€ì£¼ëŠ” ì „ëµ' ë“±)

        **4ë‹¨ê³„: ìµœì¢… ì½”ì¹­ ìƒì„± (Generate Final Coaching)**
        - ìœ„ 3ë‹¨ê³„ì—ì„œ ìˆ˜ë¦½ëœ ì „ëµì„ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ [ì¶œë ¥ JSON í˜•ì‹]ì˜ ëª¨ë“  í•­ëª©ì„ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤. ëª¨ë“  ë‚´ìš©ì€ ì§€ê¸ˆê¹Œì§€ì˜ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ê³¼ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        ---

        [ì¶œë ¥ JSON í˜•ì‹ ë° ì§€ì¹¨]
        {{
          "customer_intent": "ê³ ê°ì˜ ê°€ì¥ í•µì‹¬ì ì¸ ì§ˆë¬¸ ì˜ë„ë‚˜ ë‹ˆì¦ˆë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
          "customer_sentiment": "í˜„ì¬ ê³ ê°ì˜ ê°ì • ìƒíƒœ (ì˜ˆ: ê¶ê¸ˆí•¨, ìš°ë ¤í•¨, ê¸ì •ì , ë¶€ì •ì , ì‹ ì¤‘í•¨)",
          "customer_profile_guess": "ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì •í•œ ê³ ê° ì„±í–¥ (ì˜ˆ: ë¶„ì„í˜•, ê´€ê³„ì¤‘ì‹œí˜•, ì‹ ì¤‘í˜•)",
          "objection_handling_strategy": {{
              "predicted_objection": "AIê°€ ì˜ˆì¸¡í•˜ëŠ” ê³ ê°ì˜ ë‹¤ìŒ ë°˜ë¡ ì´ë‚˜ ë§ì„¤ì„ í¬ì¸íŠ¸",
              "counter_strategy": "ì˜ˆì¸¡ëœ ë°˜ë¡ ì— ëŒ€í•œ ëŒ€ì‘ ì „ëµ ìš”ì•½",
              "example_script": "ê·¸ ì „ëµì„ í˜„ì¥ì—ì„œ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ”, 3~5ì¤„ì˜ ì„¤ë“ë ¥ ìˆëŠ” ì¶”ì²œ ë©˜íŠ¸"
          }},
          "recommended_actions": [
            {{"style": "ê³µê° ë° ê´€ê³„ í˜•ì„±", "script": "ìµœì†Œ 3~5ì¤„ì˜ í’ë¶€í•˜ê³  ìƒì„¸í•˜ë©°, ì§„ì‹¬ì´ ë‹´ê¸´ êµ¬ì²´ì ì¸ ë©˜íŠ¸"}},
            {{"style": "í•µì‹¬ ë‹ˆì¦ˆ í™•ì¸ ì§ˆë¬¸", "script": "ê³ ê°ì˜ ë‹ˆì¦ˆë¥¼ ë” ëª…í™•íˆ í•˜ê±°ë‚˜, ìˆ¨ê²¨ì§„ ë‹ˆì¦ˆë¥¼ ë°œê²¬í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì§ˆë¬¸ ë©˜íŠ¸"}},
            {{"style": "ë…¼ë¦¬ì  ì„¤ë“ ë° ì •ë³´ ì œê³µ", "script": "ìµœì†Œ 3~5ì¤„ì˜ í’ë¶€í•˜ê³  ìƒì„¸í•˜ë©°, ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì²´ì ì¸ ë©˜íŠ¸"}},
            {{"style": "ë‹¤ìŒ ë‹¨ê³„ ìœ ë„ ë° ì§ˆë¬¸", "script": "ìµœì†Œ 3~5ì¤„ì˜ í’ë¶€í•˜ê³  ìƒì„¸í•˜ë©°, ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ëŒ€í™”ë¥¼ ì´ëŒì–´ë‚´ëŠ” êµ¬ì²´ì ì¸ ì§ˆë¬¸ ë©˜íŠ¸"}}
          ],
          "next_step_strategy": "í˜„ì¬ ìƒí™©ì—ì„œ ê°€ì¥ íš¨ê³¼ì ì¸ ë‹¤ìŒ ìƒë‹´ ì§„í–‰ ë°©í–¥ ë° ì „ëµì— ëŒ€í•œ ì¡°ì–¸"
        }}

        ---
        [ë¶„ì„ì— ì°¸ê³ í•  ì „ë¬¸ê°€ ì§€ì‹ (RAG ê²°ê³¼)]
        {knowledge_str}
        ---
        [ì´ì „ ìƒë‹´ ë§¥ë½]
        {history_str}
        ---
        [í˜„ì¬ ìƒë‹´ ë‚´ìš©]
        {consultation_text}
        ---
        """

    def analyze_consultation(self, consultation_text, history):
        """[ìˆ˜ì •ë¨] ê¸´ í…ìŠ¤íŠ¸ëŠ” ìš”ì•½ í›„ ë¶„ì„í•˜ê³ , AIì˜ ì°¨ë‹¨ ì‘ë‹µ ë“± ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ê°•í™”í•©ë‹ˆë‹¤."""
        if not consultation_text.strip(): 
            return None, history, "ë¶„ì„í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        try:
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½ ë‹¨ê³„ë¥¼ ë¨¼ì € ê±°ì¹©ë‹ˆë‹¤.
            processed_text = self._summarize_if_needed(consultation_text)
            
            relevant_knowledge = self.retrieve_relevant_knowledge(processed_text)
            prompt = self._build_prompt(processed_text, history, relevant_knowledge)
            
            response = self.model.generate_content(prompt)
            
            # [ì¶”ê°€ë¨] AI ì‘ë‹µì— ë¬¸ì œê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.
            if not response.parts:
                if response.prompt_feedback.block_reason:
                    error_msg = f"AI ë‹µë³€ì´ ì•ˆì „ ë¬¸ì œë¡œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ìœ : {response.prompt_feedback.block_reason.name}"
                    print(f"ğŸ”¥ {error_msg}")
                    return None, history, error_msg
                else:
                    error_msg = "AIë¡œë¶€í„° ë¹„ì–´ìˆëŠ” ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤."
                    print(f"ğŸ”¥ {error_msg}")
                    return None, history, error_msg
            
            coaching_result = json.loads(response.text)
            new_history = history + [f"---ê³ ê°/ì„¤ê³„ì‚¬ ëŒ€í™”---\n{consultation_text}", f"---AI ì½”ì¹­ ìš”ì•½---\n{coaching_result.get('customer_intent')}"]
            return coaching_result, new_history, None # ì„±ê³µ ì‹œì—ëŠ” ì—ëŸ¬ ë©”ì‹œì§€ ì—†ìŒ (None)

        except json.JSONDecodeError as e:
            error_msg = f"AIê°€ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {e}"
            print(f"ğŸ”¥ {error_msg}\nAIì˜ ì›ë³¸ ì‘ë‹µ: {response.text[:500]}...")
            return None, history, error_msg
        except Exception as e:
            error_msg = f"AI ë¶„ì„ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}"
            print(f"ğŸ”¥ {error_msg}")
            return None, history, error_msg